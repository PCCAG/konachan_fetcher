## coding=utf-8
import asyncio
from loguru import logger  # pip install loguru
import multiprocessing
import concurrent.futures
import os
from cellfunctions_ import (
    get_source,
    parse,
    save_img,
    read_headers_from_json,
    ensure_file_exists,
)
import os
from dotenv import load_dotenv
import pandas
import random

# åŠ è½½é…ç½®æ–‡ä»¶
load_dotenv()
# proxies=None

# ä¸»å‡½æ•°
# 3ä¸ªå¤§ä»»åŠ¡ä¾æ¬¡ä¼ é€’å‚æ•°
# è¿™é‡Œå¯ä»¥ç”¨é˜Ÿåˆ—è¿›ä¸€æ­¥æ”¹,æ‡’å¾—æ”¹äº†ğŸ˜…,æˆ‘çœ‹å¾—çœ¼èŠ±
# å¾—åˆ°æ•°æ®


@logger.catch()
async def main(
    pids: list[int],
    sem_times: int = int(os.getenv("sem_times")),  # å¹¶å‘æ•° åœ¨.envé…ç½®
    imgpath: str = os.getenv("IMG_PATH"),  # ä¿å­˜å›¾ç‰‡è·¯å¾„,åœ¨.envé…ç½®
    headers: dict = read_headers_from_json(),  # è¯·æ±‚å¤´
) -> list | list[tuple[int, str, str, str]]:  # [(pid,tags,img_path,img_link),....]
    #
    #
    # å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
    if not os.path.exists(imgpath):
        os.mkdir(imgpath)
        logger.warning("å›¾ç‰‡è·¯å¾„ä¸å­˜åœ¨ï¼Œå·²åˆ›å»º")
    #

    # å¹¶å‘è·å–æºç 
    # pidsæ˜¯ä¸€ä¸ªpidåˆ—è¡¨ [pid,...]
    # å¦‚é“¾æ¥ https://konachan.com/post/show/361874 pidæŒ‡çš„æ˜¯361874 ç±»å‹int
    async def process_urls(pids: list[int]):
        sem = asyncio.Semaphore(sem_times)  # å¹¶å‘æ•°
        async with sem:
            tasks = []  # å¹¶å‘ä»»åŠ¡åˆ—è¡¨
            for pid in pids:
                host_path = f"https://konachan.com/post/show/{pid}/"

                # tasks.append(asyncio.ensure_future(get_source(pid,host_path)))
                # The asyncio.ensure_future() function is deprecated in Python 3.10 in favor of asyncio.create_task().
                tasks.append(asyncio.create_task(get_source(pid, host_path, headers)))

            r = await asyncio.gather(*tasks, return_exceptions=False)
            # å‚æ•°
            results = [
                (i, ii) for i, ii in r if ii != "å¯„"
            ]  # pid_source=[(pid,source),......]
            return results

    # pid_source=[(pid,source),......]
    pid_source = await process_urls(pids)
    if len(pid_source) == 0:
        return []  # ç¬¬ä¸€æ­¥æ²¡æœ‰ä¸œè¥¿åé¢ä¹Ÿå°±æ²¡æœ‰å¿…è¦ç»§ç»­äº†

    # å¤šè¿›ç¨‹è§£æ
    def run_tasks(task, pid_source: list[tuple[int, str]]):
        max_workers = min(len(pid_source), multiprocessing.cpu_count())
        results = []  # ç»“æœåˆ—è¡¨
        with concurrent.futures.ProcessPoolExecutor(
            max_workers=max_workers
        ) as executor:
            futures = [
                executor.submit(task, pid, source)
                for pid, source in pid_source
                if source != "å¯„"
            ]
            for future in concurrent.futures.as_completed(
                futures
            ):  # all futureså®Œæˆæ—¶çš„iterableå¯¹è±¡
                try:
                    results.append(future.result())
                    # logger.success("parse......")
                except Exception as e:
                    logger.warning("å¼•å‘ ä¸€ä¸ª parse error...")
                    # print(future.result())
                    # logger.warning(e)
                    continue
        return results

    pid_img_link_tags = run_tasks(parse, pid_source)
    if len(pid_img_link_tags) == 0:
        return []  # ç¬¬äºŒæ­¥æ²¡æœ‰ä¸œè¥¿åé¢ä¹Ÿå°±æ²¡æœ‰å¿…è¦ç»§ç»­äº†

    # å¹¶å‘ä¸‹è½½å›¾ç‰‡
    async def download_imgs(pid_img_link_tags: list[tuple[int, str, str]]):
        sem = asyncio.Semaphore(sem_times)  # å¹¶å‘æ•°
        async with sem:
            tasks = []  # å¹¶å‘ä»»åŠ¡åˆ—è¡¨

            for pid, img_link, tags in pid_img_link_tags:
                if tags == "å¯„" or img_link == "å¯„":
                    logger.error("æœªçŸ¥è§£ææˆ–ä¸‹è½½é”™è¯¯å¼•èµ·...å¯„")
                    continue
                else:
                    tasks.append(
                        asyncio.create_task(
                            save_img(pid, img_link, tags, headers, imgpath)
                        )
                    )
                    # pin += 1
                # logger.info("append download img task.....")
            results = await asyncio.gather(*tasks)

            results = [
                (pid, tags, img_path, img_link)
                for pid, tags, img_path, img_link in results
                if tags != "å¯„" and img_link != "å¯„" and img_path != "å¯„"
            ]

            # print(results)

            logger.success(f"downloaded {len(results)} img to IMG_PATH......")
            return results

    pid_tags_img_link_img_path = await download_imgs(pid_img_link_tags)

    return pid_tags_img_link_img_path
    # è¿”å›kimgè¡¨çš„å¾ˆå¤šè¡Œçš„ä¿¡æ¯


# example test
if __name__ == "__main__":
    for _ in range(int(os.getenv("times"))):
        pids = random.sample(
            list(range(int(os.getenv("low")), int(os.getenv("upper")) + 1)),
            int(os.getenv("down_number")),
        )
        print(f"å•æ¬¡å¹¶å‘æ•°é‡: {pids.__len__()}")
        # headers = read_headers_from_json()

        rows = asyncio.run(main(pids))

        nowtime = pandas.Timestamp.now().strftime("%Y-%m-%d %H:%M:%S")

        data = [
            (pid, tags, img_link, img_path, 1, nowtime)
            for pid, tags, img_link, img_path in rows
        ]

        df = pandas.DataFrame(
            columns=("pid", "tags", "link", "path", "status", "time"), data=data
        )

        # è‡ªå®šä¹‰å‡½æ•°ç¡®ä¿æ–‡ä»¶å­˜åœ¨
        if ensure_file_exists("./Data/kimg.csv") == False:
            df.to_csv("./Data/kimg.csv", index=False, mode="w")
        ensure_file_exists("./Data/tags.csv")

        df.to_csv(
            "./Data/kimg.csv",
            index=False,
            mode="a",
            header=False,
        )
        # ./Data/tags.csv

        row_tags: list = df["tags"].to_list()

        tags_set: set = set()
        # for tags in row_tags:
        #     for tag in tags.split(" "):
        #         tags_set.add(tag)
        # ä½¿ç”¨å†…ç½®çš„é›†åˆæ“ä½œ
        tags_set.update(tag for tags in row_tags for tag in tags.split(" "))

        try:
            alltags_existed_set: set = set(
                pandas.read_csv("./Data/tags.csv").iloc[:, 0].to_list()
            )
        except Exception as e:
            alltags_existed_set: set = set()
            pass

        need_add_tags: list = list(tags_set - alltags_existed_set)

        # è¿½åŠ è¿›å»çš„æ˜¯åº”è¯¥ä¸ºåŸè¡¨ä¸­ä¸å­˜åœ¨çš„

        pandas.DataFrame(data=need_add_tags, index=None, columns=None).to_csv(
            "./Data/tags.csv", mode="a", index=False, header=False
        )

        # with open("./Data/tags.csv", "a", encoding="UTF-8") as f:
        #     f.writelines()
