## coding=utf-8
import asyncio
import functools
import json
import os
import random
import re as re__
from rich.progress import Progress
from rich.style import Style
from rich.progress import (
    BarColumn,
    DownloadColumn,
    Progress,
    TaskID,
    TextColumn,
    TimeRemainingColumn,
    TransferSpeedColumn,
    SpinnerColumn,
    TimeElapsedColumn,
)

# import types

# å¼‚æ­¥ä¿å­˜æ–‡ä»¶çš„åº“
# pip install aiofiles
import aiofiles
import httpx
from bs4 import BeautifulSoup
from dotenv import load_dotenv

# from fake_useragent import UserAgent
from loguru import logger

# from playwright.sync_api import sync_playwright  # , Playwright

# ä¸€ä¸ªplaywrightçš„æ’ä»¶ç”¨æ¥ä¼ªè£…æ— å¤´æ¨¡å¼
# pip install playwright-stealth
# from playwright_stealth import stealth_sync

from parse_tags_link import f_link, f_tags


# åŠ è½½é…ç½®æ–‡ä»¶
load_dotenv()


##kç«™ä¸»é¡µ
host = "https://konachan.com"

# # åˆ©ç”¨clashä»£ç†è½¬å‘
# proxies = {"http://": "http://127.0.0.1:10809", "https://": "http://127.0.0.1:10809"}
http_proxy = os.getenv("http_proxy")
http_proxy2 = os.getenv("http_proxy2")

if not http_proxy2.startswith("http://"):
    http_proxy2 = http_proxy

proxies = {"http://": http_proxy, "https://": http_proxy}
proxies2 = {"http://": http_proxy2, "https://": http_proxy2}
proxies_list = [proxies, proxies2]

# logger.warning(f"ä»£ç†: {http_proxy}")

# # httpxçš„socks5ä»£ç†å¥½åƒæœ‰é—®é¢˜
# socks5_proxies = {
#     "http://": "socks5://127.0.0.1:62333",
#     "https://": "socks5://127.0.0.1:62333",
# }

# proxies=None


def read_headers_from_json(
    cookie_json_filepath="_cookies_.json", headers_example="_headers_example.json"
) -> dict:
    """
    é»˜è®¤:
    ä» headers_example="_headers_ example.json" è·å–headersæ¨¡æ¿,
    ä» cookie_json_filepath="cookies.json" æ›´æ–°headersçš„cookieå­—æ®µ,
    å¦‚æœå¤±è´¥è°ƒç”¨get_headers(),
    è¿”å›: headers
    """

    # logger.debug("å°è¯•ä»cookies.jsonè·å–headers çš„cookie.......")
    with open(cookie_json_filepath, encoding="utf-8") as f:
        try:
            # dread = dict(json.load(f))
            d_list: list = json.load(f)
            # dict().keys()
            # print(list(dread.keys())[0])
            headers_cookie = "; ".join([f'{d["name"]}={d["value"]}' for d in d_list])
            with open(headers_example, encoding="utf-8") as h:
                headers = dict(json.load(h))
                headers["cookie"] = headers_cookie
            # print(headers)
        except Exception as e:
            # raise e
            # raise NameError("Not found headers") from e
            logger.warning(
                "å°è¯•ä»cookies.jsonè·å–headers çš„cookieå¤±è´¥,å°†ç”¨å‡½æ•°get_headers()é‡‡ç”¨playwrightæ— å¤´æ¨¡å¼ä¸‹è‡ªåŠ¨è·å–headers"
            )
            # headers = get_headers()
            # headers = {}
            breakpoint()
            raise e

        # logger.success("è·å–headersæˆåŠŸ......")

        return headers


# ä¸€ä¸ªè·å–å½“å‰ipçš„å‡½æ•°
async def current_ip():
    """
    ä¸€ä¸ªè·å–å½“å‰ipçš„å‡½æ•°
    """
    async with httpx.AsyncClient() as c:
        try:
            re = await c.get(
                "http://whois.pconline.com.cn/ipJson.jsp", params={"json": "true"}
            )
            return re.json() if len(re.json()["ip"]) > 4 else {"ip": "æ²¡æœ‰è·å–åˆ°"}
        except Exception as e:
            raise e


# åˆ©ç”¨playwrightè·å–cookieåŠheaders
# @logger.catch()
# def get_headers() -> dict[str, str]:
#     """
#     åˆ©ç”¨playwrightè·å–cookieåŠheaders
#     """
#     # å¯åŠ¨æ¼”å¥
#     with sync_playwright() as p:
#         try:
#             logger.debug("åˆ©ç”¨playwrightè·å–cookieåŠheaders......")
#             # å¯åŠ¨æµè§ˆå™¨
#             b = p.webkit.launch(
#                 headless=True, proxy={"server": proxies[list(proxies.keys())[0]]}
#             )
#             logger.debug("å¯åŠ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡....")
#             # å¯åŠ¨æµè§ˆå™¨ä¸Šä¸‹æ–‡
#             context = b.new_context()

#             page = context.new_page()
#             # æ— å¤´æ¨¡å¼ä¼ªè£…
#             stealth_sync(page)

#             # è·¯ç”±,æµäº§å›¾ç‰‡,å®ç°æ— å›¾æ¨¡å¼
#             page.route(
#                 re__.compile(r"(\.png$)|(\.jpg$)|(\.gif$)", re__.S),
#                 lambda route: route.abort(),
#             )

#             re = page.goto(host)
#             page.click("#links > a:nth-child(1)")

#             page.wait_for_load_state("domcontentloaded", timeout=10000)
#             page.click("#post-list-posts > li > div > a")

#             page.wait_for_load_state("domcontentloaded", timeout=10000)

#             # è·å–æ‰€æœ‰cookie
#             cookies = context.cookies()
#             # è·å–è¯·æ±‚å¤´
#             headers = re.request.headers
#             headers["cookie"] = "".join(
#                 f"{i['name']}={i['value']};"
#                 if pin != len(cookies) - 1
#                 else f"{i['name']}={i['value']}"
#                 for pin, i in enumerate(cookies)
#             )
#             headers["Referer"] = r"https://konachan.com/post"

#             with open("_headers_.json", "w", encoding="UTF-8", errors="ignore") as f:
#                 json.dump(headers, fp=f, ensure_ascii=False, indent=2)

#             page.close()
#             context.close()
#             b.close

#             logger.success("è·å–cookieåŠheadersæˆåŠŸ")

#             return headers
#         except Exception as e:
#             logger.error("å–cookieåŠheaderså¤±è´¥,è¯·å°è¯•æ£€æŸ¥ä»£ç†æ˜¯å¦å‡ºé”™")
#             breakpoint()
#             raise e


class Counter:
    def __init__(self) -> None:
        pass

    # é»˜è®¤
    class PROCESS_BAR_NONE:
        def __init__(self) -> None:
            pass
            self.n: int = 0
            self.total: int = 1

        def update(*arg, **kwargs):
            pass

        def close(self):
            pass

    @staticmethod
    def counter_async(PROCESS_BAR=PROCESS_BAR_NONE()):
        """
        å‚æ•°è£…é¥°å™¨ : ä¼ å…¥PROCESS_BAR å®ç°å¯¹åŸå‡½æ•°è¿›åº¦æ§åˆ¶.
        ä¾‹å¦‚: PROCESS_BAR = tqdm.tqdm(total=200, desc="Processing", unit="item"),
        tqdm.tqdmè¿›åº¦æ¡(import tqdm),
        éœ€è¦åœ¨å…¶ä»–æ–‡ä»¶å¯¼å…¥å¹¶è¦†å†™åŸå¼‚æ­¥å‡½æ•°,
        newfunc = counter_async(PROCESS_BAR=tqdm.tqdm(total=200, desc="Test", unit="item"))(example)
        """
        ##PROCESS_BAR = tqdm.tqdm()

        def async_counter(func):
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                result = await func(*args, **kwargs)
                wrapper.processcount.update(1)
                if wrapper.processcount.n == wrapper.processcount.total:
                    wrapper.processcount.close()

                return result

            wrapper.processcount = async_counter.processcount
            return wrapper

        async_counter.processcount = PROCESS_BAR
        return async_counter

    @staticmethod
    def counter_sync(PROCESS_BAR=PROCESS_BAR_NONE()):
        """
        ä¸æ”¯æŒå¤šè¿›ç¨‹ğŸ˜…
        """

        def sync_counter(func):
            @functools.wraps(func)
            def wrapper(*args, **kwargs):
                r = func(*args, **kwargs)
                wrapper.processcount.update(1)
                if wrapper.processcount.n == wrapper.processcount.total:
                    wrapper.processcount.close()
                return r

            wrapper.processcount = sync_counter.processcount
            return wrapper

        sync_counter.processcount = PROCESS_BAR
        return sync_counter

    @staticmethod
    def counter_async_rich(
        description: str,
        start: bool = True,
        total: float | None = 100,
        completed: int = 0,
        visible: bool = True,
        Progress: Progress = Progress(
            "[progress.description]{task.description}({task.completed}/{task.total})",
            SpinnerColumn(finished_text="[green]âœ”"),
            BarColumn(
                style=Style(color="red"),
                complete_style=Style(color="green", bold=True),
                finished_style=Style(color="green"),
            ),
            "[progress.percentage]{task.percentage:>3.2f}%",
            "[yellow]â±",
            TimeElapsedColumn(),
            # "[cyan]â³",
            # TimeRemainingColumn(),
            # TransferSpeedColumn(),
        ),
        **fields,
    ):
        """
                å°è£…rich Processçš„ä¸€ä¸ªå‚æ•°è£…é¥°å™¨

                (method) def add_task(
            description: str,
            start: bool = True,
            total: float | None = 100,
            completed: int = 0,
            visible: bool = True,
            **fields: Any
        ) -> TaskID
        Add a new 'task' to the Progress display.

        Args:
            description (str): A description of the task.
            start (bool, optional): Start the task immediately (to calculate elapsed time). If set to False,
                you will need to call start manually. Defaults to True.
            total (float, optional): Number of total steps in the progress if known.
                Set to None to render a pulsing animation. Defaults to 100.
            completed (int, optional): Number of steps completed so far. Defaults to 0.
            visible (bool, optional): Enable display of the task. Defaults to True.
            **fields (str): Additional data fields required for rendering.

        Returns:
            TaskID: An ID you can use when calling update.

        """
        # process = Progress(
        #     "[progress.description]{task.description}({task.completed}/{task.total})",
        #     SpinnerColumn(finished_text="[green]âœ”"),
        #     BarColumn(
        #         style=Style(color="red"),
        #         complete_style=Style(color="green", bold=True),
        #         finished_style=Style(color="green"),
        #     ),
        #     "[progress.percentage]{task.percentage:>3.2f}%",
        #     "[yellow]â±",
        #     TimeElapsedColumn(),
        #     # "[cyan]â³",
        #     # TimeRemainingColumn(),
        #     # TransferSpeedColumn(),
        # )
        process = Progress
        process_bar = process.add_task(
            description=description,
            start=start,
            total=total,
            completed=completed,
            visible=visible,
            fields=fields,
        )
        process.start()

        def async_counter(func):
            @functools.wraps(func)
            async def wrapper(*args, **kwargs):
                result = await func(*args, **kwargs)
                wrapper.process.update(wrapper.process_bar, advance=1, refresh=True)
                if (
                    wrapper.process.tasks[wrapper.process_bar].completed
                    == wrapper.process.tasks[wrapper.process_bar].total
                ):
                    wrapper.process.stop()
                return result

            wrapper.process_bar = async_counter.process_bar
            wrapper.process = async_counter.process
            return wrapper

        async_counter.process_bar = process_bar
        async_counter.process = process
        return async_counter


async def get_source(
    pid: int,
    url: str,
    headers: dict,
    proxies: dict = proxies_list[0],
) -> tuple[int, str]:
    """
    è·å–å•ä¸ªé¡µé¢æºç 
    return: pid, source

    """
    # sourcery skip: remove-unreachable-code
    # å¼‚æ­¥ä¸Šä¸‹æ–‡èœå•ç®¡ç†å™¨
    async with httpx.AsyncClient(proxies=proxies) as client:
        # è¿™ä¸ªæ˜¯é‡è¯•20æ¬¡,2333ğŸ¤£
        for i in range(20):
            try:
                # headers["user-agent"] = UserAgent().random
                re = await client.get(
                    url,
                    headers=headers,
                    timeout=(i + 1) * 50,
                    # proxies=random.sample(proxies_list, 1)[0],
                )
                res = re.text
                if "<p>This post does not exist.</p>" in res or (
                    "This post was deleted." in res
                    and """<div class="status-notice">""" in res
                ):
                    logger.error(f"{pid}å›¾ç‰‡ä¸å­˜åœ¨æˆ–è€…è¢«åˆ é™¤äº†")
                    logger.error(f"https://konachan.com/post/show/{pid}/")
                    return (pid, "å¯„")
                elif len(res) < 2000:
                    logger.warning("æºç é•¿åº¦ä¸å¯¹")
                    await asyncio.sleep(random.randint(1, 4))
                    logger.warning(f"https://konachan.com/post/show/{pid}/")
                    continue
                elif re.status_code == 403:
                    logger.error("403æ— æ³•è®¿é—®")
                    return (pid, "å¯„")
                elif re.status_code == 200:
                    logger.success("è·å–æºç æˆåŠŸ")
                    return (pid, res)
            except Exception as e:
                # raise e
                logger.warning(f"ä¸‹è½½æºç é‡è¯•: https://konachan.com/post/show/{pid}")
                await asyncio.sleep(random.randint(1, 4))
                # raise e
                # lg.warning("re link")
                continue
        logger.error("æºç  nothing!")
        logger.error(f"https://konachan.com/post/show/{pid}/")
        return (pid, "å¯„")


# è§£ææºç å¾—åˆ°å›¾ç‰‡åœ°å€å’Œtags
# @counter
def parse(pid: int, source: str) -> tuple[int, str, str]:
    """
    è§£ææºç å¾—åˆ°å›¾ç‰‡åœ°å€å’Œtags.
    return: pid,tags,img_link
    """
    # sourcery skip: remove-redundant-continue, remove-unnecessary-else
    # global df_error
    try:
        tags_link = [
            pid,
        ]
        # æ‰€æœ‰è§£æå™¨è¯•ä¸€é.23333ğŸ¤£
        for param_features in (
            "lxml",
            # "html.parser",
            # "html5lib",
            "html",
            "html5",
            "xml",
            "lxml-xml",
        ):
            soup = BeautifulSoup(source, features=param_features)
            tags = f_tags(soup)
            link = f_link(soup)
            if (tags != False) and (link != False):
                tags_link.extend((link, tags))
                break
            else:
                continue
        if len(tags_link) == 3:
            return tuple(tags_link)
        else:
            logger.error(f"è§£æé”™è¯¯last: https://konachan.com/post/show/{pid}/")
            return (pid, "å¯„", "å¯„")
    except Exception as e:
        logger.error(f"è§£æé”™è¯¯all:  https://konachan.com/post/show/{pid}/")
        return (pid, "å¯„", "å¯„")
        # raise e


# ä¸‹è½½å›¾ç‰‡
# @counter
async def save_img(
    pid: int,
    img_link: str,
    tags: str,
    headers: dict,
    imgpath: str,
    proxies: dict = proxies_list[1],
) -> tuple[int, str, str, str]:
    """
    ä¸‹è½½å›¾ç‰‡.
    è¿”å›: return (pid, tags, img_link, img_path)
    """
    # "D:\Kimge\part14\360035.jpg"

    # é˜²æ­¢é‡å¤ä¸‹è½½

    for extension in ["jpg", "gif", "png"]:
        filepath = f"{imgpath}/{pid}.{extension}"
        if os.path.exists(filepath) == True:
            logger.warning(f"æœ¬åœ°å·²å­˜åœ¨æ–‡ä»¶:{filepath}")
            return (pid, tags, img_link, filepath)

    async def check_ifsuccess_return_responce():
        async with httpx.AsyncClient(proxies=proxies) as clinet:
            for _ in range(20):
                try:
                    # headers["user-agent"] = UserAgent().random
                    re = await clinet.get(
                        img_link,
                        headers=headers,
                        timeout=300,
                        # proxies=random.sample(proxies_list, 1)[0],
                    )
                    assert re.status_code == 200, "è¯·æ±‚å›¾ç‰‡çŠ¶æ€ç :{re.status_code}"
                    return re
                except Exception:
                    logger.warning(f"ä¸‹è½½å›¾ç‰‡é‡è¯•: https://konachan.com/post/show/{pid}")
                    await asyncio.sleep(random.randint(1, 4))
                    continue
            return False

    try:
        re = await check_ifsuccess_return_responce()

        # è¿™é‡Œéå¼‚æ­¥

        if re == False:
            logger.error("è¯·æ±‚å›¾ç‰‡é“¾æ¥é”™è¯¯")
            logger.error(f"https://konachan.com/post/show/{pid}/")
            return (pid, "å¯„", "å¯„", "å¯„")
        # logger.debug(f"è¯·æ±‚å›¾ç‰‡çŠ¶æ€ç :{re.status_code}")

        elif re.status_code != 200:
            logger.error(f"è¯·æ±‚å›¾ç‰‡çŠ¶æ€ç :{re.status_code}")
            logger.error(f"https://konachan.com/post/show/{pid}/")
            return (pid, "å¯„", "å¯„", "å¯„")
        else:
            img_type = img_link.split(".")[-1]
            # logger.info(f"å›¾ç‰‡ç±»å‹: {img_type}")

            # å›¾ç‰‡è·¯å¾„
            img_path = f"{imgpath}/{pid}.{img_type}"

            # logger.info(f"å›¾ç‰‡æµç±»å‹: {type(re.content)}") äºŒè¿›åˆ¶

            # ä½¿ç”¨å¼‚æ­¥å†™å…¥æ–‡ä»¶

            # breakpoint()

            async with aiofiles.open(img_path, "wb") as f:
                await f.write(re.content)
                # logger.debug(f"ä¿å­˜å›¾ç‰‡ä¸­......{pid}")

            if tags != "å¯„" and img_link != "å¯„" and img_path != "å¯„":
                logger.success(f"ä¸‹è½½å›¾ç‰‡æˆåŠŸ: {img_path}")
                return (pid, tags, img_link, img_path)

            else:
                logger.error("æ²¡æœ‰æœ‰æ•ˆçš„å€¼,ä¸‹è½½å›¾ç‰‡å¤±è´¥")

                logger.error(f"https://konachan.com/post/show/{pid}/")

                return (pid, "å¯„", "å¯„", "å¯„")

    except Exception as e:
        logger.error("ä¿å­˜å›¾ç‰‡åˆ°è·¯å¾„é”™è¯¯")

        logger.error(f"https://konachan.com/post/show/{pid}/")

        # breakpoint()

        return (pid, "å¯„", "å¯„", "å¯„")


# ğŸ˜…
def ensure_file_exists(filepath, file_ecoding="UTF-8") -> bool:
    """
    æ£€æµ‹æ–‡ä»¶è·¯å¾„æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºæ–‡ä»¶ã€‚

    å‚æ•°ï¼š
    - filepath: æ–‡ä»¶è·¯å¾„
    - file_ecoding: åˆ›å»ºçš„æ–‡ä»¶ç¼–ç 
    return:
    Ture è¿™ä¸ªæ–‡ä»¶å­˜åœ¨
    False åä¹‹
    """
    try:
        # ğŸ¤”
        with open(filepath, "r", errors="ignore"):
            pass
        return True
    except FileNotFoundError:
        # os.makedirs("/".join(filepath.split("/")[:-1]))
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, "w", errors="ignore", encoding=file_ecoding):
            pass
        return False
    except Exception:
        print("constom function:  ensure_file_exists,  raise an unknown error ! ?")


def count_rechange_files_directory(
    path: str,
    recursion_count_begin: int = 1,
    mix_recursion_count: int = 100,
    maximum_capacity: int = 100,
) -> str:
    """
    æ™ºèƒ½è·¯å¾„, é˜²æ­¢è·¯å¾„ä¸‹æ–‡ä»¶å¤ªå¤š(æ–‡ä»¶å¤¹å†…æ–‡ä»¶å¤ªå¤šå°†ä¼šå½±å“èµ„æºç®¡ç†å™¨åŠ è½½é€Ÿåº¦ğŸ˜…),
    å¦‚æœæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶æ•°é‡è¶…è¿‡ maximum_capacity.
    å°†åœ¨åŸæ–‡ä»¶è·¯å¾„åé¢åŠ ä¸€ä¸ªæ•°å­—åˆ›å»ºä¸€ä¸ªæ–°è·¯å¾„,æ•°å­—åˆå§‹æ˜¯ recursion_count_begin.
    å¦‚æœæ–‡ä»¶å¤¹ä¸‹çš„æ–‡ä»¶æ•°é‡è¿˜æ˜¯è¶…è¿‡ maximum_capacity,
    è¿™ä¸ªæ•°å­—ä¼šå¢åŠ ç›´åˆ°è¾¾åˆ° mix_recursion_count.
    ä»¥é€’å½’æ–¹å¼è¿­ä»£.
    return è¿”å›ä¸€ä¸ªæ–°è·¯å¾„.
    """
    origin_path: str = path

    def recursion(
        path: str = path, recursion_count_begin: int = recursion_count_begin - 1
    ):
        if not os.path.exists(path):
            try:
                logger.warning(f"åˆ›å»ºè·¯å¾„:{path}")
                os.mkdir(path)
            except FileNotFoundError:
                logger.warning(f"å†æ¬¡åˆ›å»ºè·¯å¾„:{path}")
                os.makedirs(path)
            except Exception:
                logger.error(f"åˆ›å»ºè·¯å¾„æœªçŸ¥é”™è¯¯,è¯·æŸ¥çœ‹è·¯å¾„æ˜¯å¦æœ‰é—®é¢˜,å°†è¿”å›åŸè·¯å¾„:{path} ")
                return path
            logger.warning(f"è·¯å¾„ä¸å­˜åœ¨ï¼Œå·²åˆ›å»º: {path}")
        files_number = os.listdir(path).__len__()
        logger.debug("files_number: {}".format(files_number))
        if (
            files_number > maximum_capacity
            and recursion_count_begin < mix_recursion_count
        ):
            # py3.12
            logger.warning(
                f"è·¯å¾„ä¸‹æ–‡ä»¶å¤ªå¤š, å°†é‡æ–°åˆ›å»º: {f'{origin_path}{recursion_count_begin+1}'}"
            )
            return recursion(
                f"{origin_path}{recursion_count_begin+1}",
                recursion_count_begin + 1,
            )
        else:
            logger.success(f"æœ€ç»ˆè·¯å¾„:{path}")

            return path

    output_path = recursion()
    return output_path


# # æ£€æµ‹å¹¶åˆ›å»ºæ–‡ä»¶è·¯å¾„
# file_path = r"path\to\your\file.txt"
# ensure_file_exists(file_path)
